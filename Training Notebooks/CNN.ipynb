{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":10011380,"datasetId":6151870,"databundleVersionId":10280967}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import h5py\nimport numpy as np\nfrom torch.utils.data import Dataset\n\nclass SudokuDataset(Dataset):\n    def __init__(self, h5_file_path, transform=None):\n        self.h5_file_path = h5_file_path\n        self.transform = transform\n\n        # Load the HDF5 data\n        with h5py.File(h5_file_path, 'r') as f:\n            self.images = np.array(f['images'])  # Shape: (N, 84, 84)\n            self.labels = np.array(f['labels'])  # Shape: (N,)\n        if len(self.images) > len(self.labels):\n            print(f\"Trimming images from {len(self.images)} to {len(self.labels)} to match labels.\")\n            self.images = self.images[:len(self.labels)]\n        \n        #print(f\"Number of images: {len(self.images)}, Number of labels: {len(self.labels)}\")\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]  # Shape: (84, 84)\n        label = self.labels[idx]  # Label\n\n        # Reshape and normalize the image\n        image = image.reshape(1, 84, 84).astype(np.float32) / 255.0  # Shape: (1, 84, 84)\n\n        return image, label\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T17:42:44.976236Z","iopub.execute_input":"2024-11-25T17:42:44.976993Z","iopub.status.idle":"2024-11-25T17:42:48.247628Z","shell.execute_reply.started":"2024-11-25T17:42:44.976950Z","shell.execute_reply":"2024-11-25T17:42:48.246771Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Subset\nfrom collections import Counter\nfrom torchvision import transforms\n\n# Dataset transformation\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n])\n\n# Load Dataset from separate files\ntrain_file_path = '/kaggle/input/sudoku-images-based-on-mnist/sudoku_training_set.h5'  # Update with your training file path\nval_file_path = '/kaggle/input/sudoku-images-based-on-mnist/sudoku_validation_images_20k.h5'  # Update with your validation file path\ntest_file_path = '/kaggle/input/sudoku-images-based-on-mnist/sudoku_testing_set.h5'\n# Assuming the dataset class can accept a file path\ntrain_dataset = SudokuDataset(train_file_path, transform=transform)\nval_dataset = SudokuDataset(val_file_path, transform=transform)\ntest_dataset = SudokuDataset(test_file_path, transform=transform)\n\n# Step 1: Determine Class Distribution in Training Dataset\nall_labels = [train_dataset[i][1] for i in range(len(train_dataset))]  # Get all labels from the train set\nclass_counts = Counter(all_labels)  # Count samples per class\nprint(\"Class Distribution in Training Set:\", class_counts)\n\n# Step 2: Identify Minority Class Count\nmin_class_count = min(class_counts.values())\n\n# Step 3: Balance the Training Dataset\nbalanced_train_indices = []\nclass_sample_counts = {cls: 0 for cls in class_counts.keys()}\n\n# Balance only the training dataset\nfor idx, (data, label) in enumerate(train_dataset):\n    if class_sample_counts[label] < min_class_count:\n        balanced_train_indices.append(idx)\n        class_sample_counts[label] += 1\n\n# Create a balanced subset of the training dataset\nbalanced_train_dataset = Subset(train_dataset, balanced_train_indices)\nprint(\"Balanced Train Dataset Size:\", len(balanced_train_dataset))\n\n# Step 4: Create DataLoaders\ntrain_loader = DataLoader(balanced_train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\n# Output Dataset Information\nprint(f\"Train Dataset Size: {len(balanced_train_dataset)}\")\nprint(f\"Validation Dataset Size: {len(val_dataset)}\")\nprint(f\"Test Dataset Size: {len(test_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T18:19:25.173897Z","iopub.execute_input":"2024-11-25T18:19:25.174371Z","iopub.status.idle":"2024-11-25T18:19:49.408575Z","shell.execute_reply.started":"2024-11-25T18:19:25.174341Z","shell.execute_reply":"2024-11-25T18:19:49.407746Z"}},"outputs":[{"name":"stdout","text":"Trimming images from 440000 to 435000 to match labels.\nClass Distribution in Training Set: Counter({False: 250000, True: 185000})\nBalanced Train Dataset Size: 370000\nTrain Dataset Size: 370000\nValidation Dataset Size: 10000\nTest Dataset Size: 30000\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nfor i in  train_loader:\n    print(i[1].shape)\n    image = i[0][0].squeeze(0)\n    plt.imshow(image.numpy(), cmap='gray')\n    plt.title(\"Grayscale Image\")\n    plt.axis('off')\n    plt.show()\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T17:43:12.971119Z","iopub.execute_input":"2024-11-25T17:43:12.971554Z","iopub.status.idle":"2024-11-25T17:43:13.268096Z","shell.execute_reply.started":"2024-11-25T17:43:12.971525Z","shell.execute_reply":"2024-11-25T17:43:13.267281Z"}},"outputs":[{"name":"stdout","text":"torch.Size([64])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\n# Define the CNN model with one additional convolutional layer\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),  # [B, 16, 84, 84]\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),                # [B, 16, 42, 42]\n\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1), # [B, 32, 42, 42]\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),                 # [B, 32, 21, 21]\n\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), # [B, 64, 21, 21]\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),                 # [B, 64, 10, 10]\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), # [B, 128, 10, 10]\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)                  # [B, 128, 5, 5]\n        )\n        self.fc_layers = nn.Sequential(\n            nn.Flatten(),                                          # [B, 128 * 5 * 5]\n            nn.Linear(128 * 5 * 5, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1),                                     # Output: 1 value per input\n            nn.Sigmoid()                                           # Probability of class 1\n        )\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = self.fc_layers(x)\n        return x\n\n# Hyperparameters\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = SimpleCNN().to(device)\ncriterion = nn.BCELoss()  # Binary Cross-Entropy Loss\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nepochs = 10\n\ndef validate(model, val_loader):\n    model.eval()  # Set the model to evaluation mode\n    correct = 0\n    total = 0\n\n    with torch.no_grad():  # Disable gradient computation\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.float().to(device)\n\n            # Forward pass\n            outputs = model(images).squeeze(1)  # Shape: [batch_size]\n            preds = (outputs > 0.5).float()  # Convert probabilities to 0/1 predictions\n\n            # Metrics\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    accuracy = 100 * correct / total\n    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n    return accuracy\n#validate(model, val_loader)\n\n# Training loop\ndef train(model, train_loader, criterion, optimizer, epochs):\n    model.train()\n    for epoch in range(epochs):\n        epoch_loss = 0.0\n        correct = 0\n        total = 0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.float().to(device)\n\n            # Forward pass\n            outputs = model(images).squeeze(1)  # Shape: [batch_size]\n            loss = criterion(outputs, labels)\n\n            # Backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Metrics\n            epoch_loss += loss.item()\n            preds = (outputs > 0.5).float()  # Convert probabilities to 0/1 predictions\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n        accuracy = 100 * correct / total\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n        validate(model, val_loader)\n# Assuming train_loader is defined elsewhere\ntrain(model, train_loader, criterion, optimizer, epochs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T17:53:42.600363Z","iopub.execute_input":"2024-11-25T17:53:42.600705Z","iopub.status.idle":"2024-11-25T18:03:31.336135Z","shell.execute_reply.started":"2024-11-25T17:53:42.600675Z","shell.execute_reply":"2024-11-25T18:03:31.335096Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 3489.0836, Accuracy: 61.61%\nValidation Accuracy: 64.03%\nEpoch 2/10, Loss: 2926.2130, Accuracy: 71.29%\nValidation Accuracy: 72.03%\nEpoch 3/10, Loss: 2497.8402, Accuracy: 77.48%\nValidation Accuracy: 76.39%\nEpoch 4/10, Loss: 2162.1592, Accuracy: 81.71%\nValidation Accuracy: 79.75%\nEpoch 5/10, Loss: 1870.5696, Accuracy: 84.96%\nValidation Accuracy: 82.69%\nEpoch 6/10, Loss: 1648.5252, Accuracy: 87.32%\nValidation Accuracy: 84.73%\nEpoch 7/10, Loss: 1485.4664, Accuracy: 88.86%\nValidation Accuracy: 85.51%\nEpoch 8/10, Loss: 1349.2334, Accuracy: 90.08%\nValidation Accuracy: 86.67%\nEpoch 9/10, Loss: 1232.0068, Accuracy: 91.02%\nValidation Accuracy: 86.23%\nEpoch 10/10, Loss: 1132.6352, Accuracy: 91.86%\nValidation Accuracy: 87.38%\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train(model, train_loader, criterion, optimizer, epochs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T18:04:44.552209Z","iopub.execute_input":"2024-11-25T18:04:44.552551Z","iopub.status.idle":"2024-11-25T18:14:32.698811Z","shell.execute_reply.started":"2024-11-25T18:04:44.552522Z","shell.execute_reply":"2024-11-25T18:14:32.697869Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 1035.2847, Accuracy: 92.64%\nValidation Accuracy: 86.94%\nEpoch 2/10, Loss: 939.7390, Accuracy: 93.38%\nValidation Accuracy: 87.84%\nEpoch 3/10, Loss: 858.8483, Accuracy: 93.99%\nValidation Accuracy: 86.63%\nEpoch 4/10, Loss: 783.0919, Accuracy: 94.53%\nValidation Accuracy: 87.82%\nEpoch 5/10, Loss: 710.4970, Accuracy: 95.06%\nValidation Accuracy: 87.85%\nEpoch 6/10, Loss: 644.7842, Accuracy: 95.56%\nValidation Accuracy: 87.22%\nEpoch 7/10, Loss: 587.9784, Accuracy: 95.94%\nValidation Accuracy: 86.54%\nEpoch 8/10, Loss: 532.9042, Accuracy: 96.37%\nValidation Accuracy: 87.35%\nEpoch 9/10, Loss: 491.0299, Accuracy: 96.65%\nValidation Accuracy: 87.69%\nEpoch 10/10, Loss: 450.3299, Accuracy: 96.94%\nValidation Accuracy: 86.65%\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"train(model, train_loader, criterion, optimizer, epochs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\ndef test(model, test_loader, num_classes):\n    model.eval()  # Set the model to evaluation mode\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():  # Disable gradient computation\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.long().to(device)\n\n            # Forward pass\n            outputs = model(images).squeeze(1)  # Shape: [batch_size]\n            preds = (outputs > 0.5).float()  # Convert probabilities to 0/1 predictions\n\n            # Collect all predictions and labels\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Convert to numpy arrays for metric calculations\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n\n    # Metrics\n    accuracy = 100 * (all_preds == all_labels).sum() / len(all_labels)\n    precision = precision_score(all_labels, all_preds, zero_division=0)\n    recall = recall_score(all_labels, all_preds, zero_division=0)\n    f1 = f1_score(all_labels, all_preds, zero_division=0)\n\n    # Per-class accuracy\n    per_class_accuracy = []\n    for cls in range(num_classes):\n        class_indices = (all_labels == cls)\n        class_correct = (all_preds[class_indices] == all_labels[class_indices]).sum()\n        class_total = class_indices.sum()\n        per_class_acc = 100 * class_correct / class_total if class_total > 0 else 0\n        per_class_accuracy.append(per_class_acc)\n\n    print(f\"Test Metrics:\")\n    print(f\"  Accuracy: {accuracy:.2f}%\")\n    print(f\"  Precision: {precision:.4f}\")\n    print(f\"  Recall:    {recall:.4f}\")\n    print(f\"  F1 Score:  {f1:.4f}\")\n    print(\"  Per-Class Accuracy:\")\n    for i, acc in enumerate(per_class_accuracy):\n        print(f\"    Class {i}: {acc:.2f}%\")\n\n    return accuracy, precision, recall, f1, per_class_accuracy\n\n    \ntest(model, test_loader, 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T18:28:40.857864Z","iopub.execute_input":"2024-11-25T18:28:40.858594Z","iopub.status.idle":"2024-11-25T18:28:42.929445Z","shell.execute_reply.started":"2024-11-25T18:28:40.858544Z","shell.execute_reply":"2024-11-25T18:28:42.928495Z"}},"outputs":[{"name":"stdout","text":"Test Metrics:\n  Accuracy: 87.00%\n  Precision: 0.8945\n  Recall:    0.8389\n  F1 Score:  0.8658\n  Per-Class Accuracy:\n    Class 0: 90.11%\n    Class 1: 83.89%\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(86.99666666666667,\n 0.8945048695528542,\n 0.8388666666666666,\n 0.8657928234767951,\n [90.10666666666667, 83.88666666666667])"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"save_path = 'model.pth'\ntorch.save(model.state_dict(), save_path)\nprint(f\"Model saved to {save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T18:23:05.442024Z","iopub.execute_input":"2024-11-25T18:23:05.442663Z","iopub.status.idle":"2024-11-25T18:23:05.453449Z","shell.execute_reply.started":"2024-11-25T18:23:05.442625Z","shell.execute_reply":"2024-11-25T18:23:05.452430Z"}},"outputs":[{"name":"stdout","text":"Model saved to model.pth\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}